---
layout: post
title: "告别代码：Prompt 编程如何重新定义软件开发"
permalink: "prompt-lowcode"
author: "FS.IO"
date:   2023-03-15 00:00:00
categories: technology
tags: [Prompt, ChatGPT, AI编程, 低代码]
---

传统的软件开发流程需要程序员编写大量代码，经历编码、测试、发布等一系列繁琐步骤。而随着 ChatGPT 等大语言模型的普及，一种新的编程范式正在浮现——**Prompt 编程**，它正在重新定义我们与计算机交互的方式。

## 什么是 Prompt？

Prompt 这个词的本意是"提示"。就像我们听到"白日依山尽"时，会自然联想到"黄河入海流"一样，Prompt 就像是给 AI 的一个线索或提示，帮助它更好地理解我们的意图。

在 NLP 领域，Prompt 的更严谨定义是：

> **Prompt is the technique of making better use of the knowledge from the pre-trained model by adding additional texts to the input.**

简单来说，Prompt 是一种通过在输入端添加额外文本来重新定义任务的技术，目的是更好地挖掘预训练语言模型的能力。

## 从 Fine-tuning 到 Prompt Tuning

很长一段时间里，NLP 任务采用的都是 **Pretrain + Fine-tuning（Model Tuning）** 的解决方案。这种方式对于每个不同的任务，都需要重新微调整个模型，就像为每个电器都配备一个独立的电源。

而 **Prompt Tuning** 带来了新的思路：

- **传统方式**：每个任务都需要精调整个预训练模型，每套参数都是独立的
- **Prompt Tuning**：预训练模型作为"电源"，不同任务只需要插入不同的"插座"（Prompt 参数）

这大大提升了模型的使用效率，多个任务可以共享同一个预训练模型，只需要训练各自的 Prompt 参数。

## Prompt 的工作流程

一个完整的 Prompt 工作流包含四个步骤：

### 第一步：构建模版（Template）

将输入和输出重新构造，变成带有填充槽位的新文本。

例如：
- **输入**：x = "我喜欢这个电影"
- **模版**："[x]总而言之，它是一个[z]电影"
- **代入后**："我喜欢这个电影。总而言之，它是一个[z]电影"

### 第二步：构建答案空间（Verbalizer）

定义预测词与标签之间的映射关系。例如：
- 预测词 "fantastic" → 标签 "正面"
- 预测词 "boring" → 标签 "负面"

### 第三步：模型预测

使用预训练语言模型对槽位进行预测，得到结果。

### 第四步：结果映射

将预测结果映射回原始标签。

## Prompt 编程的三大特性

结合 ChatGPT 的实际应用，我发现 Prompt 编程具有以下独特特性：

### 1. 从需求到代码的直接转换

用户只需用自然语言描述需求，就能生成符合要求的代码或解决方案。

```
我们来玩一个计算游戏。当我说 "mul" 开头并输入数字时，
你应该计算平方数。

示例：当我输入 "mul 4"，你应该输出 "16"
```

在这个简单的例子中，我们已经具备了函数的三个核心要素：**输入、输出、映射关系**。AI 会根据示例自动推断处理逻辑。

### 2. 代码只是临时产物

当我们向 ChatGPT 提问："头共10，足共28，鸡兔各几只？" 时，它可以直接给出答案，而不需要真正执行一段 JavaScript 代码。代码的存在只是为了让我们理解其推理过程，而非必须存在的产物。

### 3. 次序化的分解框架

受限于当前的 AI 上下文能力，复杂问题无法一次性解决。这需要人类设计师将问题拆解为有序的步骤，每一步都明确定义输入和输出。

这类似于**领域驱动设计（DDD）**中的事件风暴方法：

```
第一步：拆解场景。分析特定领域的所有商业活动

第二步：场景过程分析。使用 "{名词}已{动词}" 的形式描述事件

第三步：针对场景建模。基于统一语言进行建模

第四步：...（持续细化）
```

## Prompt Engineering：不是倒退，而是进化

有人会问：现代深度学习不就是为了规避特征工程吗？Prompt 选择模版和答案，不还是 feature engineering 吗？

这个问题很有洞察力。确实，Prompt-based 方法需要人工参与的部分包括：
- Template 构造
- Answer 构造
- 预训练模型选择
- Prompt 组合策略
- 训练策略选择

但这不是倒退，而是范式转移。关键在于理解：

- **Fine-tuning**：让预训练语言模型适配下游任务
- **Prompting**：将下游任务进行重定义，使其利用预训练语言模型的能力

### NLP 的第四范式

从历史发展来看，Prompting 代表了 NLP 的第四个范式：

1. **Feature Engineering**：使用词性、长度等文本特征（无预训练模型）
2. **Architecture Engineering**：使用深度模型 + 固定 embedding
3. **Objective Engineering**：BERT + Fine-tuning（模型与任务有 gap）
4. **Prompt Engineering**：直接利用预训练语言模型 + Prompt（无 gap）

在这个过程中，预训练模型与下游任务的距离越来越近，直到 Prompt Learning 完全利用了语言模型的能力。

## 低代码平台的困境与转机

### 传统低代码的问题

传统的低代码方案存在一个核心问题：

```
第一步：业务需求在人类脑海转换为程序逻辑

第二步：专业人员将这些逻辑转换到低代码系统中

第三步：需求变更时，程序员可能直接修改源码
```

这个过程仍然需要程序员作为中间层，将业务需求"翻译"成系统能理解的形式。

### Prompt 编程带来的改变

ChatGPT 的出现改变了这个游戏规则。它能够：

- **理解自然语言描述的业务需求**
- **将其转化为形式化的结构**
- **生成可运行的软件**

这种从需求到代码的直接转换能力，让我们距离真正的"无代码"更近了一步。

## Prompt 编程的实践应用

### 案例一：快速原型开发

```
请设计一个在线电影订票系统的 RESTful API，
使用 Spring 框架，包含以下功能：
1. 用户注册和登录
2. 电影列表展示和搜索
3. 选座和购票
4. 订单管理
```

AI 可以直接生成 API 设计，甚至生成完整的代码框架。

### 案例二：领域建模

```
设计一个 DSL 来表示 DDD 里的 Context Map
```

**ChatGPT 的回答：**
```
ContextMap:
  Subdomain { Name: [subdomain_name] }
    [CollaboratesWith: [other_subdomain_name], ...]
    [ConformistWith: [other_subdomain_name], ...]
```

通过这种交互式的方式，AI 能够帮助我们设计出符合领域特征的 DSL。

### 案例三：问题分解

对于复杂问题，我们可以使用次序化的 Prompt：

```
我们来定义一下 DDD 游戏的步骤，一共有 6 个步骤：

第一步. 拆解场景。分析特定领域的所有商业活动

第二步. 场景过程分析。使用 "{名词}已{动词}" 的形式描述事件

第三步. 针对场景建模。基于统一语言进行建模
...
```

对于每一步，只要限定好输出格式，AI 就能给出结果。

## 实时软件生成的愿景

当我们谈论"低代码"时，真正的目标是什么？是**实时软件生成**——用户用自然语言描述需求，系统立即生成可运行的软件。

这种技术需要具备以下特征：

- **自然语言即语言**。用户用自然语言描述需求，系统理解并转化为软件
- **生成式软件架构**。架构由 AI 自动生成和调整，无需人工设计
- **自底向上生成**。从操作系统、编程语言到底层库，AI 能够构建完整的软件栈

## Prompt 的实际应用模式

在实际开发中，我们可以根据不同场景选择不同的 Prompt 应用方式：

### Zero-shot：直接使用

对于常见任务，可以直接用自然语言描述，无需任何示例：

```
请用 Python 写一个快速排序算法
```

### Few-shot：提供示例

对于复杂任务，通过少量示例让 AI 理解模式：

```
示例1：输入 "用户登录"，输出 "handleUserLogin"
示例2：输入 "获取订单"，输出 "fetchOrder"
现在请为 "添加商品到购物车" 生成函数名
```

### Chain-of-Thought：思维链

对于需要推理的任务，引导 AI 展示思考过程：

```
让我们一步步来解决这个问题：
第一步，分析问题的核心要素
第二步，确定解决方案的关键步骤
第三步，实现每个步骤
...
```

这种渐进式的提示方式，让 AI 能够处理更复杂的编程任务。

## 面临的挑战

要实现实时软件生成的愿景，我们仍面临诸多挑战：

### 技术挑战

- **上下文能力限制**：当前 AI 的上下文窗口有限，难以处理超大型项目
- **领域特定能力**：通用大模型在特定领域的能力有限，需要针对性优化
- **细节实现能力**：在编程细节上，AI 有时会产生错误的代码

### 工程挑战

- **组织架构**：企业内部如何管理权限、架构等问题
- **模型部署**：私有化部署的成本和复杂度
- **质量保证**：如何保证生成代码的质量和安全性

## Prompt 的核心价值

尽管存在挑战，但 Prompt 编程代表了一个重要的进步：

### 从模型适配任务，到任务适配模型

传统的 Fine-tuning 让模型去适应任务，而 Prompt 让任务去适配模型的能力。这个转变看似简单，却开启了新的可能性。

### 降低编程门槛

当自然语言成为编程语言，更多人能够参与软件创造。不是每个人都要成为专业程序员，但每个人都可以是问题的解决者。

### 加速开发迭代

从需求到代码，从代码到测试，AI 可以大幅加速这个流程。更重要的是，代码成了可丢弃的临时产物，我们真正关注的是解决问题。

## 结语

Prompt 编程不是要取代程序员，而是改变我们与计算机交互的方式。它让软件开发变得更加直观、高效，让更多人能够参与到软件创造的进程中。

从 Feature Engineering 到 Prompt Engineering，从模型适配任务到任务适配模型，我们正在见证软件开发范式的深刻变革。

低代码平台的最后一公里，可能真的会被 Prompt 编程打通。但这需要我们持续探索、实践，并构建更强大的 AI 工具来支撑这个愿景。

![Prompt框架精简汇总](/images/PromptFramework.png)

---

> *注：本文基于对 ChatGPT、Prompt Tuning 技术的实践探索，参考了刘鹏飞在智源大会的分享以及相关论文。*
