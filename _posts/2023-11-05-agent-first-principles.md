---
layout: post
title: "从第一性原理看大模型 Agent 技术"
permalink: "agent-first-principles"
author: "FS.IO"
date:   2023-11-05 00:00:00
categories: technology
---

互联网时代，网站是核心载体；移动互联网时代，App 占据了人们的注意力中心。那么，智能时代呢？

一个大胆的预测：**Agent 可能成为智能时代的核心载体**。

## 什么是 Agent？

从第一性原理来看，Agent 是一个能感知环境、自主决策并采取行动的实体。人类是这个星球上最强大的 Agent，但 Agent 的复杂程度各不相同——从简单的恒温器到复杂的国家组织，都可以是 Agent。

**Agent 的关键特征：**
- 感知环境
- 自主决策
- 行动能力
- 明确目标
- 适应和学习能力

这个概念在 AI 领域已经研究了几十年，但始终面临技术天花板。为什么？因为 **Agent 技术的进步本质上依赖 AGI（通用人工智能）的进步**。

直到大模型的出现，这一切开始改变。

## 从 Prompt 到 Agent：技术演进脉络

如果我们观察过去一年多的技术发展，会看到一个清晰的脉络：

```
Prompt 工程 → Prompt Chain/Flow → Agent → Multi-Agent
```

### 第一阶段：Prompt 工程

最简单的方式是把大模型当成工具，通过精心设计的 Prompt 来调用。角色扮演、零样本/少样本提示，都是这种思路的体现。

还记得那个 15000 字符的"AI 导师" Prompt 吗？这就是 Prompt 工程的极致发挥。

### 第二阶段：Prompt 外挂

单纯靠 Prompt 不够用了。人们开始给大模型加"外挂"：

- **向量数据库**：让模型使用最新知识
- **工具调用**：ChatGPT Plugins 让模型能调用外部 API
- **规划器**：把问题转化成 PDDL 格式，让专用规划器解决

### 第三阶段：思维链与分解

要让大模型像人类一样"一步一步思考"，思维链（Chain of Thought）应运而生。

进一步的发展：
- **CoT-SC**：尝试多种思路，投票选择最佳答案
- **思维树（ToT）**：将问题垂直分解，逐层扩散解空间
- **思维图（GoT）**：既可以分解，也可以合并
- **累计推理**：清华姚期智团队提出，在 24 点问题上达到 98% SOTA

### 第四阶段：ReAct 与反馈

ReAct 将推理和行动结合起来：**Thought → Action → Observation**，形成闭环。

ChatGPT 的代码解释器就是这种模式——生成代码、调用工具、获取结果、反馈给用户。

更进一步，Reflection 机制让 Agent 能从每次任务中积累经验，无论成败。

### 第五阶段：Agent

AutoGPT 的横空出世标志着 Agent 时代的到来。它的核心思想：

1. 创建初始计划
2. 进入主循环：决策 → 执行 → 反馈 → 迭代
3. 支持任务分解和子 Agent 调用
4. 通过记忆机制优化决策

最近清华发布的 **XAgent** 提出"双循环机制"——外循环负责宏观规划，内循环负责细节执行，在效果上碾压了 AutoGPT。

### 第六阶段：Multi-Agent

单智能体不够？那就多智能体协作。

**斯坦福小镇**：每个角色都是一个 Agent，按计划活动，相遇时交谈，涌现出群体智能。

**MetaGPT**：定义产品经理、架构师、工程师等角色，协作完成 500 行代码的小工程。

## 智能的核心：面向目标架构

从人类智能的视角来看，Agent 技术的本质是什么？

答案可能是：**面向目标架构（Goal-Oriented Architecture）**。

### 系统一与系统二

《思考快与慢》中提出的系统 1 和系统 2 概念：

- **系统 1**：快速反应、直觉、潜意识
- **系统 2**：逻辑思考、推理、有意识

在认知科学中，全局工作空间理论（GWT）认为系统 2 是一个高度集中的"舞台"，我们的有意识思考都在这个舞台上进行。

### 目标驱动的智能

人类智能的核心是什么？是**消除当前状态和目标状态之间的差异**。

```
当前世界状态 → [目标驱动] → 目标世界状态
```

在这个过程中：
- 我们构建世界模型
- 通过手段-目的分析（means-ends）找到解决方案
- 将复杂任务分解为子任务
- 遇到异常时灵活调整

这正是 Agent 需要具备的能力。

### 软件工程的范式转移

传统的软件开发是**面向过程架构**——函数、接口、组件，都是被调用的子流程，不为结果负责。

而 Agent 代表了**面向目标架构**——描述目标，让系统自行寻找达成目标的方法。

这个转移意味着：
- 从人类主导、AI 辅助 → AI 主导、人类辅助
- 从解决有限任务 → 解决无限长尾任务
- 从垂直层级架构 → 自主生成的架构

## 现有 Agent 的局限性

尽管发展迅速，但现有 Agent 技术仍有明显局限：

### 1. 缺乏真正的推理能力

很多 Agent 只是简单的规划器，没有显性的推理过程。它们能行动，但不会深度思考。

### 2. 世界模型不完善

大模型只能输入语言，但理解世界需要多模态输入、时间感知、身体运动控制等。

### 3. 记忆机制简陋

目前的"记忆"只是向量数据库存储和召回，缺乏：
- 记忆的整理和遗忘
- 长短时记忆的层次化
- 工作记忆的机制

### 4. 学习能力不足

Agent 需要学会：
- 判断自身可靠性
- 知道自己知道什么、不知道什么
- 从经验中内化知识

### 5. 简单难题做不了

举个例子：让 GPT-4 展示一个超长加法计算的每一步过程。由于 Token 限制，它无法完成，但人类可以。

这说明人类和 AI 的处理策略有本质差异，我们需要新的架构来弥补这个 Gap。

## 未来的方向

基于第一性原理的分析，Agent 技术的未来可能在以下方向：

### 1. 中央执行机构

不只是规划器，而是有透明可控的内部加工过程。用系统 2 包裹起来，让每一步思考都可观察。

### 2. 完善的记忆机制

- 记忆的整理和遗忘
- 长短时记忆与工作记忆的层次化
- 海马体式的记忆重构

### 3. 多模态输入与自上而下处理

不仅是视觉、听觉，还要有时间感知、身体感知。更重要的是 **Projection 机制**——从上到下的解释，像人类从像素点中识别人脸。

### 4. 隐空间通信

语言是低带宽、低效的通信工具。未来 Agent 能否在隐空间直接通信，类似"心灵感应"？

### 5. 运动控制的层次化

神经网络直接连接运动控制神经网络，实现流畅的、比人类更灵活的运动。

### 6. Mental Simulation

不是"想到就做"，而是在内部预判行动结果，自我纠错，保证行动可靠性。

## 思考：Agent 与大模型

一个重要的问题：**GPT-4 和 Agent，谁更本质？**

从任务完成的视角看，GPT-4 也是一种 Agent。Agent 的概念是大模型的超集。

这也解释了为什么智能时代的核心载体可能是 Agent，而不是大模型本身。大模型是 Agent 的核心组件，就像自行车轮子和自行车的关系。

## 结语

Agent 技术站在了一个新的起点上。

从 Prompt 工程到 AutoGPT，从单智能体到多智能体协作，我们正在见证一场深刻的变革。

它不是要取代人类，而是要重新定义人机协作的方式。

未来的智能体工程，可能会让 AI 成为中心，人类变为辅助。这不是悲观，而是乐观——因为这意味着我们可以从重复的脑力劳动中解放出来，去探索更有创造性的领域。

正如毛泽东的那段话：

> "它是站在海岸遥望海中已经看得见桅杆尖头了的一只航船，它是立于高山之巅远看东方已见光芒四射喷薄欲出的一轮朝日，它是躁动于母腹中的快要成熟了的一个婴儿。"

Agent 技术，正是这样一个时刻。

---

> *注：本文基于【从第一性原理看大模型Agent技术】分享视频整理，感谢原作者的深入思考。*
